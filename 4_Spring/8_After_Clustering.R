# ------------------------------------------------------------------------------
# Data Filtering and Joining Clustering IDs for Analysis
# ------------------------------------------------------------------------------


# Description:
# This script processes migratory tracking data by:
#   - Filtering data based on day/night classification and time intervals
#   - Identifying and removing outliers in clustering features
#   - Joining clustering IDs with other variables for both day and night datasets
# 
# Input:
#   - Processed tracking data with clustering features: 'Spring_Deviation.csv'
#   - Clustering IDs for day: 'Spring_Day_with_ClusterID.csv'
#   - Clustering IDs for night: 'Spring_Night_with_ClusterID.csv'

# Note:
# The input files 'Spring_Day_with_ClusterID.csv' and 'Spring_Night_with_ClusterID.csv'
# must be generated by running the Python script "2_AHC_Clustering" located in 
# the "5_Clustering" folder.
# 
# 
# Output:
#   - Processed and clustered day data: 'SpringDay_Clustered.csv'
#   - Processed and clustered night data: 'SpringNight_Clustered.csv'

# ------------------------------------------------------------------------------

# Load Required Libraries
library(dplyr)

# ------------------------------------------------------------------------------
# Step 1: Load Tracking Data
# ------------------------------------------------------------------------------

rm(list=ls())

tracking_data <- read.csv("Spring_Deviation.csv") 


# Convert the timestamp column to POSIXct format for time-based operations
tracking_data$timePosix <- as.POSIXct(tracking_data$timePosix, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")


# ------------------------------------------------------------------------------
# Step 2: Calculate Time Intervals and Filter Data
# ------------------------------------------------------------------------------

# Calculate time intervals between consecutive GPS fixes
tracking_data <- tracking_data %>%
  group_by(idyear) %>%
  mutate(time_interval = difftime(lead(timePosix), timePosix, units = 'mins'))

# Filter data to retain points with time intervals less than 10 minutes
filtered_data <- tracking_data %>% filter(time_interval < 10) 


# ------------------------------------------------------------------------------
# Step 3: Filter Day and Night Data
# ------------------------------------------------------------------------------

# Split data into day and night subsets based on the 'night' column
day_data <- filtered_data %>% filter(night == 0)  
night_data <- filtered_data %>% filter(night == 1)  

# Remove IDs with insufficient data points (minimum thresholds: 80 for day, 20 for night)
day_data <- day_data %>% group_by(idyear) %>% filter(n() >= 80) %>% ungroup()
night_data <- night_data %>% group_by(idyear) %>% filter(n() >= 20) %>% ungroup()



# ------------------------------------------------------------------------------
# Step 4: Identify Outliers and Filter Clustering Features
# ------------------------------------------------------------------------------

# Define clustering feature columns for day and night
CF_columns_day <- c("delta_MagHeading2", "delta_apparent_dip", "delta_inclination",
                    "wind_support", "crosswind", "Distance.to.Coast")

CF_columns_night <- c("delta_MagHeading2", "delta_apparent_dip", "delta_inclination",
                      "wind_support", "crosswind", "Distance.to.Coast")


# Define the outlier threshold (number of standard deviations)
outlier_threshold <- 5

# Remove outliers for day data
outlier_filter <- apply(day_data[CF_columns_day], 2, function(col) {
  abs(col - mean(col)) <= outlier_threshold * sd(col)
})

day_filtered <- day_data[apply(outlier_filter, 1, all), ]  


# Remove outliers for night data
outlier_filterN <- apply(night_data[CF_columns_night], 2, function(col) {
  abs(col - mean(col)) <= outlier_threshold * sd(col)
})

night_filtered <- night_data[apply(outlier_filterN, 1, all), ]  



# ------------------------------------------------------------------------------
# Step 5: Join Clustering IDs with Filtered Data
# ------------------------------------------------------------------------------

# Load clustering IDs for day and night
ClusterID_day <- read.csv("Spring_Day_with_ClusterID.csv")
ClusterID_night <- read.csv("Spring_Night_with_ClusterID.csv")

# Specify cluster columns to join
cluster_columns_day <- c("cluster_id")     # For day, 6 clusters has been identified
cluster_columns_night <- c("cluster_id")   # For day, 9 clusters has been identified


# Join day data with clustering IDs
day_clustered <- cbind(day_filtered, ClusterID_day[cluster_columns_day])

# Join night data with clustering IDs
night_clustered <- cbind(night_filtered, ClusterID_night[cluster_columns_night])


# ------------------------------------------------------------------------------
# Step 6: Save the Clustered Data
# ------------------------------------------------------------------------------
# Save the clustered datasets
write.csv(day_clustered, "SpringDay_Clustered.csv", row.names = FALSE)
write.csv(night_clustered, "SpringNight_Clustered.csv", row.names = FALSE)


# ------------------------------------------------------------------------------
# End of Script
# ------------------------------------------------------------------------------